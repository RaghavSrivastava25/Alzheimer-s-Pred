{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ðŸ§  Alzheimer's Disease Classification","metadata":{}},{"cell_type":"markdown","source":"ðŸ•¸ï¸ A Convolutional Neural Network (CNN) model is used here to classify brain MRIs into normal, very-mild, mild and moderate Alzheimer classes. The data in total consists of 6400 images.","metadata":{}},{"cell_type":"markdown","source":"Developed as part of a project work for the **UCS 1603 Introduction to Machine Learning** Course. ðŸ“–","metadata":{}},{"cell_type":"markdown","source":"Authors:\n* Shashanka Venkatesh  - 18 5001 145\n* Suraj Jain           - 18 5001 177\n* Vishakan Subramanian - 18 5001 196\n* Vishnu Krishnan      - 18 5001 200","metadata":{}},{"cell_type":"markdown","source":"**We recommend the use of a GPU Accelerator to reduce the load on the CPU and to run the notebook faster.**","metadata":{}},{"cell_type":"markdown","source":"### Importing the necessary libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nimport os\nfrom distutils.dir_util import copy_tree, remove_tree\n\nfrom PIL import Image\nfrom random import randint\n\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import matthews_corrcoef as MCC\nfrom sklearn.metrics import balanced_accuracy_score as BAS\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nimport tensorflow_addons as tfa\nfrom keras.utils.vis_utils import plot_model\nfrom tensorflow.keras import Sequential, Input\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.layers import Conv2D, Flatten\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator as IDG\nfrom tensorflow.keras.layers import SeparableConv2D, BatchNormalization, MaxPool2D\n\n\n\nprint(\"TensorFlow Version:\", tf.__version__)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-06T08:19:30.160360Z","iopub.execute_input":"2022-11-06T08:19:30.160721Z","iopub.status.idle":"2022-11-06T08:19:38.172765Z","shell.execute_reply.started":"2022-11-06T08:19:30.160685Z","shell.execute_reply":"2022-11-06T08:19:38.171470Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"TensorFlow Version: 2.4.1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Data Pre-Processing","metadata":{}},{"cell_type":"code","source":"base_dir = \"/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/\"\nroot_dir = \"./\"\ntest_dir = base_dir + \"test/\"\ntrain_dir = base_dir + \"train/\"\nwork_dir = root_dir + \"dataset/\"\n\nif os.path.exists(work_dir):\n    remove_tree(work_dir)\n    \n\nos.mkdir(work_dir)\ncopy_tree(train_dir, work_dir)\ncopy_tree(test_dir, work_dir)\nprint(\"Working Directory Contents:\", os.listdir(work_dir))","metadata":{"execution":{"iopub.status.busy":"2022-11-06T08:20:23.424125Z","iopub.execute_input":"2022-11-06T08:20:23.424534Z","iopub.status.idle":"2022-11-06T08:20:44.784491Z","shell.execute_reply.started":"2022-11-06T08:20:23.424487Z","shell.execute_reply":"2022-11-06T08:20:44.783185Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Working Directory Contents: ['VeryMildDemented', 'MildDemented', 'ModerateDemented', 'NonDemented']\n","output_type":"stream"}]},{"cell_type":"code","source":"WORK_DIR = './dataset/'\n\nCLASSES = [ 'NonDemented',\n            'VeryMildDemented',\n            'MildDemented',\n            'ModerateDemented']\n\nIMG_SIZE = 176\nIMAGE_SIZE = [176, 176]\nDIM = (IMG_SIZE, IMG_SIZE)","metadata":{"execution":{"iopub.status.busy":"2022-11-06T08:21:03.623683Z","iopub.execute_input":"2022-11-06T08:21:03.624027Z","iopub.status.idle":"2022-11-06T08:21:03.627879Z","shell.execute_reply.started":"2022-11-06T08:21:03.623994Z","shell.execute_reply":"2022-11-06T08:21:03.627204Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#Performing Image Augmentation to have more data samples\n\nZOOM = [.99, 1.01]\nBRIGHT_RANGE = [0.8, 1.2]\nHORZ_FLIP = True\nFILL_MODE = \"constant\"\nDATA_FORMAT = \"channels_last\"\n\nwork_dr = IDG(rescale = 1./255, brightness_range=BRIGHT_RANGE, zoom_range=ZOOM, data_format=DATA_FORMAT, fill_mode=FILL_MODE, horizontal_flip=HORZ_FLIP)\n\ntrain_data_gen = work_dr.flow_from_directory(directory=WORK_DIR, target_size=DIM, batch_size=6500, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-11-06T08:21:08.970469Z","iopub.execute_input":"2022-11-06T08:21:08.971085Z","iopub.status.idle":"2022-11-06T08:21:09.298988Z","shell.execute_reply.started":"2022-11-06T08:21:08.971048Z","shell.execute_reply":"2022-11-06T08:21:09.297739Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Found 6400 images belonging to 4 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"def show_images(generator,y_pred=None):\n    \"\"\"\n    Input: An image generator,predicted labels (optional)\n    Output: Displays a grid of 9 images with lables\n    \"\"\"\n    \n    # get image lables\n    labels =dict(zip([0,1,2,3], CLASSES))\n    \n    # get a batch of images\n    x,y = generator.next()\n    \n    # display a grid of 9 images\n    plt.figure(figsize=(10, 10))\n    if y_pred is None:\n        for i in range(9):\n            ax = plt.subplot(3, 3, i + 1)\n            idx = randint(0, 6400)\n            plt.imshow(x[idx])\n            plt.axis(\"off\")\n            plt.title(\"Class:{}\".format(labels[np.argmax(y[idx])]))\n                                                     \n    else:\n        for i in range(9):\n            ax = plt.subplot(3, 3, i + 1)\n            plt.imshow(x[i])\n            plt.axis(\"off\")\n            plt.title(\"Actual:{} \\nPredicted:{}\".format(labels[np.argmax(y[i])],labels[y_pred[i]]))\n    \n# Display Train Images\nshow_images(train_data_gen)","metadata":{"execution":{"iopub.status.busy":"2022-11-06T08:21:12.827246Z","iopub.execute_input":"2022-11-06T08:21:12.827713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Retrieving the data from the ImageDataGenerator iterator\n\ntrain_data, train_labels = train_data_gen.next()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Getting to know the dimensions of our dataset\n\nprint(train_data.shape, train_labels.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Performing over-sampling of the data, since the classes are imbalanced\n\nsm = SMOTE(random_state=42)\n\ntrain_data, train_labels = sm.fit_resample(train_data.reshape(-1, IMG_SIZE * IMG_SIZE * 3), train_labels)\n\ntrain_data = train_data.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n\nprint(train_data.shape, train_labels.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Splitting the data into train, test, and validation sets\n\ntrain_data, test_data, train_labels, test_labels = train_test_split(train_data, train_labels, test_size = 0.2, random_state=42)\ntrain_data, val_data, train_labels, val_labels = train_test_split(train_data, train_labels, test_size = 0.2, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Constructing a Convolutional Neural Network Architecture","metadata":{}},{"cell_type":"code","source":"def conv_block(filters, act='relu'):\n    \"\"\"Defining a Convolutional NN block for a Sequential CNN model. \"\"\"\n    \n    block = Sequential()\n    block.add(Conv2D(filters, 3, activation=act, padding='same'))\n    block.add(Conv2D(filters, 3, activation=act, padding='same'))\n    block.add(BatchNormalization())\n    block.add(MaxPool2D())\n    \n    return block","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dense_block(units, dropout_rate, act='relu'):\n    \"\"\"Defining a Dense NN block for a Sequential CNN model. \"\"\"\n    \n    block = Sequential()\n    block.add(Dense(units, activation=act))\n    block.add(BatchNormalization())\n    block.add(Dropout(dropout_rate))\n    \n    return block","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def construct_model(act='relu'):\n    \"\"\"Constructing a Sequential CNN architecture for performing the classification task. \"\"\"\n    \n    model = Sequential([\n        Input(shape=(*IMAGE_SIZE, 3)),\n        Conv2D(16, 3, activation=act, padding='same'),\n        Conv2D(16, 3, activation=act, padding='same'),\n        MaxPool2D(),\n        conv_block(32),\n        conv_block(64),\n        conv_block(128),\n        Dropout(0.2),\n        conv_block(256),\n        Dropout(0.2),\n        Flatten(),\n        dense_block(512, 0.7),\n        dense_block(128, 0.5),\n        dense_block(64, 0.3),\n        Dense(4, activation='softmax')        \n    ], name = \"cnn_model\")\n\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Defining a custom callback function to stop training our model when accuracy goes above 99%\n\nclass MyCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if logs.get('val_acc') > 0.99:\n            print(\"\\nReached accuracy threshold! Terminating training.\")\n            self.model.stop_training = True\n            \nmy_callback = MyCallback()\n\n#EarlyStopping callback to make sure model is always learning\nearly_stopping = EarlyStopping(monitor='val_loss', patience=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Defining other parameters for our CNN model\n\nmodel = construct_model()\n\nMETRICS = [tf.keras.metrics.CategoricalAccuracy(name='acc'),\n           tf.keras.metrics.AUC(name='auc'), \n           tfa.metrics.F1Score(num_classes=4)]\n\nCALLBACKS = [my_callback]\n    \nmodel.compile(optimizer='adam',\n              loss=tf.losses.CategoricalCrossentropy(),\n              metrics=METRICS)\n\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training & Testing the Model","metadata":{}},{"cell_type":"code","source":"#Fit the training data to the model and validate it using the validation data\nEPOCHS = 100\n\nhistory = model.fit(train_data, train_labels, validation_data=(val_data, val_labels), callbacks=CALLBACKS, epochs=EPOCHS)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plotting the trend of the metrics during training\n\nfig, ax = plt.subplots(1, 3, figsize = (30, 5))\nax = ax.ravel()\n\nfor i, metric in enumerate([\"acc\", \"auc\", \"loss\"]):\n    ax[i].plot(history.history[metric])\n    ax[i].plot(history.history[\"val_\" + metric])\n    ax[i].set_title(\"Model {}\".format(metric))\n    ax[i].set_xlabel(\"Epochs\")\n    ax[i].set_ylabel(metric)\n    ax[i].legend([\"train\", \"val\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Evaluating the model on the data\n\n#train_scores = model.evaluate(train_data, train_labels)\n#val_scores = model.evaluate(val_data, val_labels)\ntest_scores = model.evaluate(test_data, test_labels)\n\n#print(\"Training Accuracy: %.2f%%\"%(train_scores[1] * 100))\n#print(\"Validation Accuracy: %.2f%%\"%(val_scores[1] * 100))\nprint(\"Testing Accuracy: %.2f%%\"%(test_scores[1] * 100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Predicting the test data\n\npred_labels = model.predict(test_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Print the classification report of the tested data\n\n#Since the labels are softmax arrays, we need to roundoff to have it in the form of 0s and 1s,\n#similar to the test_labels\ndef roundoff(arr):\n    \"\"\"To round off according to the argmax of each predicted label array. \"\"\"\n    arr[np.argwhere(arr != arr.max())] = 0\n    arr[np.argwhere(arr == arr.max())] = 1\n    return arr\n\nfor labels in pred_labels:\n    labels = roundoff(labels)\n\nprint(classification_report(test_labels, pred_labels, target_names=CLASSES))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plot the confusion matrix to understand the classification in detail\n\npred_ls = np.argmax(pred_labels, axis=1)\ntest_ls = np.argmax(test_labels, axis=1)\n\nconf_arr = confusion_matrix(test_ls, pred_ls)\n\nplt.figure(figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n\nax = sns.heatmap(conf_arr, cmap='Greens', annot=True, fmt='d', xticklabels=CLASSES, yticklabels=CLASSES)\n\nplt.title('Alzheimer\\'s Disease Diagnosis')\nplt.xlabel('Prediction')\nplt.ylabel('Truth')\nplt.show(ax)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Printing some other classification metrics\n\nprint(\"Balanced Accuracy Score: {} %\".format(round(BAS(test_ls, pred_ls) * 100, 2)))\nprint(\"Matthew's Correlation Coefficient: {} %\".format(round(MCC(test_ls, pred_ls) * 100, 2)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Saving the model for future use\n\nmodel_dir = work_dir + \"alzheimer_cnn_model\"\nmodel.save(model_dir, save_format='h5')\nos.listdir(work_dir)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pretrained_model = tf.keras.models.load_model(model_dir)\n\n#Check its architecture\nplot_model(pretrained_model, to_file=work_dir + \"model_plot.png\", show_shapes=True, show_layer_names=True)","metadata":{"execution":{"iopub.status.busy":"2022-11-06T08:20:21.659156Z","iopub.status.idle":"2022-11-06T08:20:21.659590Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Using the InceptionV3 model as a base model for the task","metadata":{}},{"cell_type":"markdown","source":"**Please check out the notebook here: \n[Inception V3 Model Notebook](https://www.kaggle.com/vishakansubramanian/alzheimer-s-disease-classification-inceptionv3)**","metadata":{}}]}